{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "import pickle\n",
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Post(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def decode(regex, sep=None):\n",
    "        if regex is None:\n",
    "            return None\n",
    "        else:\n",
    "            if sep is None:\n",
    "                return regex.group(0)\n",
    "            else:\n",
    "                return [w.strip() for w in regex.group(0).split(sep) if w != '']\n",
    "    \n",
    "    def __init__(self,entry):\n",
    "        section_regex = lambda section: r'(?<= {} \\=\\=)[\\s\\S]+?(?=\\=\\= |\\Z)'.format(section)\n",
    "        \n",
    "        self.title = entry[0]\n",
    "        self.text = entry[1]\n",
    "        cat = re.search(r'(?<=\\[\\[category:)[^\\s\\\\\\]]*',val[1],flags=re.I)\n",
    "        self.category =  cat.group(0) if cat is not None else None\n",
    "        self.intro = Post.decode(re.search(r'[\\s\\S]+(?=\\[\\[category)',self.text,re.M|re.I))\n",
    "        self.steps = Post.decode(re.search(section_regex('steps'),self.text,re.M | re.I), sep='\\n#')\n",
    "        self.tips = Post.decode(re.search(section_regex('tips'),self.text,re.M | re.I), sep='\\n*')\n",
    "        self.warnings = Post.decode(re.search(section_regex('warnings'),self.text,re.M | re.I), sep='\\n*')\n",
    "        self.tools = Post.decode(re.search(section_regex('you\\'ll need'),self.text,re.M | re.I), sep='\\n*')\n",
    "        self.related_posts = Post.decode(re.search(section_regex('related wikihows'),self.text,re.M | re.I), sep='\\n*')\n",
    "    \n",
    "    @property\n",
    "    def get_task(self):\n",
    "        subject_match = re.search(r'[\"\\'](.+)[\"\\']',self.title.lower())\n",
    "        doc = nlp(self.title.lower())\n",
    "\n",
    "        if subject_match is None:\n",
    "            return ([w.lemma_ for w in doc if w.pos_=='VERB'],[t.lemma_ for t in doc.noun_chunks])\n",
    "        action = re.sub(r'[\"\\']','',\n",
    "                       subject_match.group(0))\n",
    "        return ([action],\n",
    "                [t.lemma_ for t in doc if (t.pos_=='NOUN' or t.pos_=='PROPN') and t.text not in action])\n",
    "    \n",
    "    @property\n",
    "    def get_tool_nouns(self):\n",
    "        if self.tools is None:\n",
    "            return None\n",
    "        return set([np.lemma_ for tool in self.tools for np in nlp(tool).noun_chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_list = pickle.load(open(\"C:\\Programming\\Python\\Programs_NLP\\posts.p\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Parsing Post Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_posts = [p for p in post_list if p.tools is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with exact matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['become'], ['an exchange student', 'germany'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_posts[4000].get_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nlp(tool_posts[4000].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'camera',\n",
       " 'fundraiser',\n",
       " 'german language class',\n",
       " 'good grade',\n",
       " 'google hangout or skype account',\n",
       " 'journal',\n",
       " 'laptop',\n",
       " 'money',\n",
       " 'parental approval',\n",
       " 'part - time job',\n",
       " 'scholarship'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_posts[4000].get_tool_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionMatcher(object):\n",
    "    def __init__(self,post_list, tools_only=True):\n",
    "        if tools_only:\n",
    "            post_list = [p for p in post_list if p.tools is not None]\n",
    "        self.answer_dict = {}\n",
    "        print(\"Parsing and matching questions and answers...\")\n",
    "        self.task_title_dict = {}\n",
    "        \n",
    "        for p in tqdm_notebook(post_list):\n",
    "            task = tuple([tuple(set(i)) for i in p.get_task])\n",
    "            task = task[0] + task[1]\n",
    "            if task in self.answer_dict:\n",
    "                self.answer_dict[task].update(p.get_tool_nouns)\n",
    "                self.task_title_dict[task].append(p.title)\n",
    "            else:\n",
    "                self.answer_dict[task] = p.get_tool_nouns\n",
    "                self.task_title_dict[task] = [p.title]\n",
    "        \n",
    "                \n",
    "    @staticmethod\n",
    "    def get_task(sentence):\n",
    "        subject_match = re.search(r'[\"\\'](.+)[\"\\']',sentence.lower())\n",
    "        doc = nlp(sentence.lower())\n",
    "\n",
    "        if subject_match is None:\n",
    "            res = ([w.lemma_ for w in doc if w.pos_=='VERB'],[t.lemma_ for t in doc.noun_chunks])\n",
    "        else:    \n",
    "            action = re.sub(r'[\"\\']','', subject_match.group(0))\n",
    "            res = ([action], [t.lemma_ for t in doc if (t.pos_=='NOUN' or t.pos_=='PROPN') and t.text not in action])\n",
    "        res = tuple([tuple(set(t)) for t in res])\n",
    "        return res[0]+res[1]\n",
    "    \n",
    "    def ask(self,question):\n",
    "        parsed_question = QuestionMatcher.get_task(question)\n",
    "        if len(parsed_question)==0:\n",
    "            print(\"No idea!\")\n",
    "            return None\n",
    "        \n",
    "        if self.answer_dict.get(parsed_question) is not None:\n",
    "            return self.answer_dict[parsed_question]\n",
    "        \n",
    "        words_q = parsed_question\n",
    "        words_q_doc = [nlp(w) for w in words_q]\n",
    "        words_a = [key for key in self.answer_dict if len(key) == len(words_q)]\n",
    "        if len(words_a)==0:\n",
    "            print(\"No idea!\")\n",
    "            return None\n",
    "        \n",
    "        best_sim = 0\n",
    "        best_match = None\n",
    "        for tup in words_a:\n",
    "            sim = np.mean([q.similarity(nlp(a)) for q,a in zip(words_q_doc,tup)])\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_match = tup\n",
    "        \n",
    "        print('Total similarity: {}'.format(best_sim))\n",
    "        print(\"Matched on {}\".format(' and '.join(self.task_title_dict[best_match])))\n",
    "        return self.answer_dict[best_match]\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing and matching questions and answers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497d1f8605d0467ea8758c42020245a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "robot = QuestionMatcher(tool_posts[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total similarity: 0.8315824374943797\n",
      "Matched on Accessorize a Deck\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'basket',\n",
       " 'candle',\n",
       " 'chair',\n",
       " 'chimera',\n",
       " 'hook',\n",
       " 'light',\n",
       " 'plant',\n",
       " 'speaker',\n",
       " 'table'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.ask('build a house')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
